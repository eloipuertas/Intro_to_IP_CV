{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pybcn: https://pybcn.org/ \n",
    "\n",
    "Our code of conduct: https://pybcn.org/coc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop we are going to work with different Python libraries with image manipulation support:\n",
    "\n",
    "* Numpy  \n",
    "* Matplotlib: \n",
    "\n",
    "    `pip install matplotlib`\n",
    "\n",
    "* Pillow (PIL):\n",
    "\n",
    "    `pip install pillow`\n",
    "\n",
    "* OpenCV:\n",
    "\n",
    "  https://docs.opencv.org/4.1.0/df/d65/tutorial_table_of_content_introduction.html\n",
    "\n",
    "* Scikit image\n",
    "\n",
    "    `pip install scikit-image`\n",
    " \n",
    "* Dlib\n",
    "\n",
    "    `pip install dlib`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How an image looks like? What it's made of?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everybody have seen images but how are they internally and how can be modified or how can we obtain information from them? This is a question that we are trying to solve during this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = plt.imread('Images/camera_BW.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are composed by matrixs of values from 0 to 255 (8 bits coded):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.min(), image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "#cmap='viridis' by default.\n",
    "#plt.imshow(image,cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,4))\n",
    "\n",
    "ax1 = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "image_light = image + 25\n",
    "print(image_light.max()) #1 bytes goes from 0 to 255, overflow!!!\n",
    "ax1.imshow(image,cmap='gray')\n",
    "ax2.imshow(image_light,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece = image[100:300,220:450] #slice\n",
    "plt.imshow(piece,cmap='gray')\n",
    "piece.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with a color image? How many colors are defined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_color = plt.imread('Images/camera_RBG.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_color.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_color)\n",
    "f = plt.figure(figsize=(15,3))\n",
    "\n",
    "ax1 = f.add_subplot(131)\n",
    "ax2 = f.add_subplot(132)\n",
    "ax3 = f.add_subplot(133)\n",
    "image_color[:,:,0]\n",
    "red=ax1.imshow(image_color[:,:,0],cmap = 'Reds')\n",
    "f.colorbar(red,ax=ax1)\n",
    "green = ax2.imshow(image_color[:,:,1],cmap = 'Greens')\n",
    "f.colorbar(green,ax=ax2)\n",
    "blue = ax3.imshow(image_color[:,:,2],cmap = 'Blues')\n",
    "f.colorbar(blue,ax=ax3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Especific libraries for images : Pillow (PIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display #for display in IPython Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('Images/camera_RBG.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(im)\n",
    "#im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain some information about opened image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.format, im.size, im.mode, im.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = (200,100,450,300)\n",
    "region = im.crop(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_resize = im.resize((400, 200))\n",
    "display(im_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_rotate_45 = im.rotate(45)\n",
    "display(im_rotate_45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.2 Image color manipulation:   Equalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps, Image\n",
    "\n",
    "im1 = Image.open('Images/camera_BW.jpg')\n",
    "im2 = ImageOps.equalize(im1)\n",
    "\n",
    "display(im1)\n",
    "display(im2)\n",
    "help (\"PIL.ImageOps.equalize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "f = plt.figure(figsize=(15,3))\n",
    "\n",
    "ax1 = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "ax1.stem(im1.histogram(),linefmt = 'k-',markerfmt = 'k')\n",
    "ax2.stem(im2.histogram(), linefmt = 'k-',markerfmt = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open('Images/underwater.jpg')\n",
    "\n",
    "print (im1.size)\n",
    "im1_r = im1.resize((im1.width//3,im1.height//3))\n",
    "print (im1_r.size)\n",
    "\n",
    "im2_r = ImageOps.equalize(im1_r)\n",
    "\n",
    "display(im1_r)\n",
    "display(im2_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://manoa.hawaii.edu/exploringourfluidearth/sites/default/files/Fig9.7-LightPenetration.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "f = plt.figure(figsize=(15,3))\n",
    "\n",
    "ax1 = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "\n",
    "p = 256\n",
    "ax1.stem(im1_r.histogram()[0:p*1],linefmt = 'r-',markerfmt = 'r') #R\n",
    "ax2.stem(im2_r.histogram()[0:p*1], linefmt = 'r-',markerfmt = 'r')\n",
    "\n",
    "ax1.stem(im1_r.histogram()[p*1:p*2],linefmt = 'g-',markerfmt = 'g') #G\n",
    "ax2.stem(im2_r.histogram()[p*1:p*2], linefmt = 'g-',markerfmt = 'g')\n",
    "\n",
    "ax1.stem(im1_r.histogram()[p*2:p*3],linefmt = 'b-',markerfmt = 'b') #B\n",
    "ax2.stem(im2_r.histogram()[p*2:p*3], linefmt = 'b-',markerfmt = 'b')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.3 Image color manipulation:   Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "\n",
    "image = Image.open('Images/objects.jpg')\n",
    "image_r = image.resize((image.width//8,image.height//8))\n",
    "\n",
    "image_edges = image_r.filter(ImageFilter.FIND_EDGES)\n",
    "display(image_r)\n",
    "display(image_edges)\n",
    "help(image.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ImageFilter.FIND_EDGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 You can design your own filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ImageFilter.Kernel((3, 3),(-1, -1, -1, -1, 8, -1, -1, -1, -1),1,0)\n",
    "image_kernel = image_r.filter(kernel)\n",
    "display(image_r)\n",
    "display(image_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ImageFilter.Kernel)\n",
    "kernel = ImageFilter.Kernel((3, 3), (1, 2, 1, 2, 1, 2, 1, 2, 1),16,0)\n",
    "image_kernel = image_r.filter(kernel)\n",
    "display(image_r)\n",
    "display(image_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Can you try different kernels and effects?\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Kernel_(image_processing)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ImageFilter)\n",
    "#Kernel Kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OpenCV: Computer Vision. C++ library!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('Images/underwater.jpg')\n",
    "plt.imshow(image) #WAT!!!\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "cols = ['r','g','b']\n",
    "\n",
    "for i, c in enumerate(cols):\n",
    "    histr = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "    plt.stem(histr,linefmt = c+'-',markerfmt = c)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('Images/underwater.jpg')\n",
    "image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR TO RGB !!!\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "cols = ['r','g','b']\n",
    "\n",
    "for i, c in enumerate(cols):\n",
    "    histr = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "    plt.stem(histr,linefmt = c+'-',markerfmt = c)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Masks: Detect objects by color and size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread('Images/lemon.jpg')\n",
    "imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(imgRGB)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "cols = ['r','g','b']\n",
    "for i, c in enumerate(cols):\n",
    "    histr = cv2.calcHist([imgRGB], [i], None, [256], [0, 256])\n",
    "    plt.stem(histr,linefmt = c+'-',markerfmt = c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgBlurRGB = cv2.GaussianBlur(imgRGB, (7, 7), 0) # Smooth the image!\n",
    "plt.imshow(imgBlur)\n",
    "plt.show()\n",
    "imgHSV = cv2.cvtColor(imgBlurRGB, cv2.COLOR_RGB2HSV) #Change the Color Model !\n",
    "plt.imshow(imgHSV)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/RGB-HSV.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "\n",
    "imgRGBtiny = cv2.resize(imgBlurRGB,(360,480))\n",
    "\n",
    "\n",
    "pixel_colors = imgRGBtiny.reshape((np.shape(imgRGBtiny)[0]*np.shape(imgRGBtiny)[1], 3))\n",
    "norm = colors.Normalize(vmin=-1.,vmax=1.)\n",
    "norm.autoscale(pixel_colors)\n",
    "pixel_colors = norm(pixel_colors).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = cv2.split(imgRGBtiny)\n",
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "axis.scatter(r.flatten(), g.flatten(), b.flatten(), facecolors=pixel_colors, marker=\".\")\n",
    "axis.set_xlabel(\"Red\")\n",
    "axis.set_ylabel(\"Green\")\n",
    "axis.set_zlabel(\"Blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h, s, v = cv2.split(imgHSVtiny)\n",
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "axis.scatter(h.flatten(), s.flatten(), v.flatten(), facecolors=pixel_colors, marker=\".\")\n",
    "axis.set_xlabel(\"Hue\")\n",
    "axis.set_ylabel(\"Saturation\")\n",
    "axis.set_zlabel(\"Value\")\n",
    "plt.show()\n",
    "#Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lower_yellow = np.array([[20, 194, 120]])\n",
    "upper_yellow = np.array([25, 255, 255])\n",
    "\n",
    "# Keep only the yellow elements!!\n",
    "mask = cv2.inRange(imgHSV, lower_yellow, upper_yellow)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(mask,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Find contours!! we will keep the external points of each contourn \n",
    "cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "help (cv2.findContours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnts[0] -> img, cnts[1] -> contourns:list of points, cnts[2] hierarchy\n",
    "len(cnts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt in cnts[1]:\n",
    "    ((x, y), radius) = cv2.minEnclosingCircle(cnt) #enclose a list of points in a circle\n",
    "    if radius > 100:\n",
    "        cv2.circle(imgRGB, (int(x), int(y)), int(radius),(0, 255, 255), 20)\n",
    "    \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(imgRGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many red balls are in this image?\n",
    "![title](images/balls.jpeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting Objects Kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Perspective conversions: Photo Scan example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('Images/nota.jpg')\n",
    "img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "im_r = cv2.resize(img,(width, height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(im_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgray = cv2.cvtColor(im_r,cv2.COLOR_BGR2GRAY) # converts to gray \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(imgray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh = cv2.threshold(imgray,170,255,cv2.THRESH_BINARY) \n",
    "#Everything from 170 goes to 255, using thresh binary (sharp) \n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(thresh, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find contours! we will keep all the points for the contours\n",
    "\n",
    "_, contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#sort contours by area\n",
    "contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "im_r_copy = im_r.copy()\n",
    "# draw the first contour, the one with more area.\n",
    "cont = 0\n",
    "cv2.drawContours(im_r_copy, contours, cont, (255,0,0), 20)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(im_r_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find edge points from countour.\n",
    "peri = cv2.arcLength(contours[cont], True)\n",
    "points = cv2.approxPolyDP(contours[cont], 0.02 * peri, True)\n",
    "\n",
    "points = points.reshape(4,2)\n",
    "rect = np.zeros((4,2),dtype = 'float32')\n",
    "rect[0],rect[1],rect[2],rect[3] = points[0],points[3],points[2],points[1]\n",
    "(tl, tr, br, bl) = rect\n",
    "\n",
    "im_r_copy = im_r.copy()\n",
    "pts = np.array(rect, np.int32)\n",
    "pts = pts.reshape((-1, 1, 2))\n",
    "cv2.polylines(im_r_copy,[pts],True,(255,0,0),20)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(im_r_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Euclidean distances for each line.\n",
    "widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "print(\"wa\", widthA)\n",
    "widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "print(\"wb\",widthB)\n",
    "\n",
    "heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "print(\"ha\", heightA)\n",
    "heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "print(\"hb\",heightB)\n",
    "\n",
    "maxWidth = max(int(widthA), int(widthB))\n",
    "maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "points_dst = np.array([[0, 0],[maxWidth, 0],[maxWidth, maxHeight],\n",
    "                [0, maxHeight]], dtype = \"float32\")\n",
    "\n",
    "\n",
    "#calculate perspective transform Matrix\n",
    "M = cv2.getPerspectiveTransform(rect, points_dst)\n",
    "print(M)\n",
    "#apply perspective Transform to thresh using Transform Matrix\n",
    "scan = cv2.warpPerspective(thresh, M, (maxWidth, maxHeight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(scan, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to repair this perspective:\n",
    "![title](images/plate.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perspective KATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Machine Learning with scikit.Image:  Face Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, data, exposure\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1= data.astronaut()\n",
    "ex2 = data.coins()\n",
    "ex3 = data.coffee()\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n",
    "\n",
    "ax1.imshow(ex1)\n",
    "ax2.imshow(ex2, cmap= 'gray')\n",
    "ax3.imshow(ex3, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Face Dectection using Haar cascades (Viola & Jones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://journals.plos.org/plosone/article/figure/image?id=10.1371/journal.pone.0173424.g002&size=large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('Images/nuria.jpg')\n",
    "crop = img[0:600,200:600]\n",
    "io.imshow(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_path = '/Users/eloi/opencv/data/haarcascades/haarcascade_frontalface_alt.xml'\n",
    "faceCascade = cv2.CascadeClassifier(haar_path)\n",
    "\n",
    "print (\"it exists? \" +  str(not faceCascade.empty()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "io.imshow(gray)\n",
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=4, minSize=(50, 50),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(crop, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('Images/people.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=4, minSize=(50, 50),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "print(len(faces))    \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img)\n",
    "#GOOD but it could be better..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Second round: Face Detection Using HOG : Histogram of oriented Gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "img = io.imread('Images/nuria.jpg')\n",
    "crop = img[0:600,200:600]\n",
    "\n",
    "#create hog features\n",
    "fd, hog_image = hog(crop, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualize=True, multichannel=True, block_norm='L2-Hys')\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(hog_image, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd, hog_image2 = hog(ex1, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualize=True, multichannel=True, block_norm='L2-Hys')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(hog_image2, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_image_r = exposure.rescale_intensity(hog_image, in_range=(0, 12))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(hog_image_r, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dlib frontal_face_detector() implementation use HOG features:\n",
    "import dlib, cv2\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "faces = detector(gray, 1)\n",
    "\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces[0].area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in faces:\n",
    "    pt1,pt2 = face.tl_corner(), face.br_corner() \n",
    "    cv2.rectangle(crop, (pt1.x,pt1.y), (pt2.x,pt2.y), (255,255,255), 2)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('Images/people.jpg')\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = detector(gray, 1)\n",
    "print(len(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for face in faces:\n",
    "    pt1,pt2 = face.tl_corner(), face.br_corner() \n",
    "    cv2.rectangle(img, (pt1.x,pt1.y), (pt2.x,pt2.y), (255,255,255), 2)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img)\n",
    "#Better Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Third round: Face Detection DNN : Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('Images/people.jpg')\n",
    "dnnFaceDetector = dlib.cnn_face_detection_model_v1(\"./mmod_human_face_detector.dat\")\n",
    "faceRects = dnnFaceDetector(img,0)\n",
    "print(len(faceRects))\n",
    "for faceRect in faceRects:\n",
    "    x1 = faceRect.rect.left()\n",
    "    y1 = faceRect.rect.top()\n",
    "    x2 = faceRect.rect.right()\n",
    "    y2 = faceRect.rect.bottom()\n",
    "    cv2.rectangle(img, (x1,y1),(x2,y2), (255,255,255), 2)\n",
    "    \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img)\n",
    "#Well Done!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with this image now:\n",
    "![title](images/more_people.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try a different model for this image:\n",
    "\n",
    "![title](images/dogs.jpeg)\n",
    "\n",
    "\n",
    "https://github.com/davisking/dlib-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face detection KATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dog detection KATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some related links (tutorial and sources):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.pyimagesearch.com/  \n",
    "* https://www.learnopencv.com/  \n",
    "* https://pillow.readthedocs.io/en/latest/handbook/index.html\n",
    "* https://github.com/scikit-image/skimage-tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
